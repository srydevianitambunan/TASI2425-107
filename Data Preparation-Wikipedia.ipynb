{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ztgxLfvEZrj6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcWQH2FLiHjq",
        "outputId": "99234fb6-b78e-423c-897b-82c165598017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan path file\n",
        "file_path = \"/content/drive/MyDrive/Google Colab TA/Dataset/stemmed.txt\"\n",
        "\n",
        "try:\n",
        "    # Metode 1: Membaca file menggunakan pandas secara langsung\n",
        "    df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', on_bad_lines='skip')  # Coba separator lain jika perlu\n",
        "\n",
        "except pd.errors.ParserError:\n",
        "    try:\n",
        "        # Metode 2: Membaca baris demi baris untuk menangani baris yang salah format\n",
        "        data = []\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            for line in file:\n",
        "                try:\n",
        "                    # Misalnya, asumsi data dipisahkan dengan tab\n",
        "                    parts = line.strip().split('\\t')  # Sesuaikan delimiter jika perlu\n",
        "                    if len(parts) == 2:  # Memastikan jumlah kolom sesuai\n",
        "                        data.append(parts)\n",
        "                except Exception as e:\n",
        "                    print(f\"Skipping malformed line: {line.strip()}, Error: {e}\")\n",
        "        df = pd.DataFrame(data, columns=['col1', 'col2'])  # Ganti col1, col2 dengan nama kolom Anda\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        # Buat DataFrame kosong jika gagal\n",
        "        df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "4zeji4_SiHgO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset dengan delimiter yang berbeda (contoh: ' ||| ')\n",
        "data = []\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Memisahkan data berdasarkan delimiter\n",
        "            parts = line.strip().split(' ||| ')\n",
        "\n",
        "            # Memastikan hanya baris dengan dua kolom yang diproses\n",
        "            if len(parts) == 2:\n",
        "                data.append(parts)\n",
        "            elif len(parts) > 2:\n",
        "                # Jika lebih dari dua kolom, gabungkan sisanya ke kolom 'text'\n",
        "                data.append([parts[0], ' ||| '.join(parts[1:])])\n",
        "\n",
        "    # Konversi ke DataFrame\n",
        "    df = pd.DataFrame(data, columns=['title', 'text'])\n",
        "\n",
        "    # Menampilkan 5 data pertama untuk validasi\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkZ67mr9iHdA",
        "outputId": "cbd561c0-2233-4206-d87d-6a3f8340a99d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     title                                               text\n",
            "0   anarch  anarch polit philosophi advoc self-govern soci...\n",
            "1   autism  autism neurodevelopment disord character impai...\n",
            "2   albedo  albedo measur reflect optic bright latin albed...\n",
            "3  alabama  alabama state southeastern region unit state b...\n",
            "4    achil  greek mytholog achil uh-kill-eez greek ἀχιλλεύ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Membersihkan Data\n",
        "# Menghapus baris duplikat\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Menghapus baris dengan nilai kosong\n",
        "df.dropna(subset=['text'], inplace=True)e"
      ],
      "metadata": {
        "id": "zYvmKA-PiHZg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvHRAaFciHXB",
        "outputId": "96d33227-5b6d-49ad-c642-5c6a1d89e2b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
      ],
      "metadata": {
        "id": "74ID6BfhiHR1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menambahkan kolom untuk kategori elektronik\n",
        "keywords = [\n",
        "    \"android\", \"automation\", \"ai speaker\", \"alexa\", \"assistant\",\n",
        "    \"base station\", \"buzzer\", \"cartridge\", \"charging cable\",\n",
        "    \"controller board\", \"docking station\", \"dsp\", \"dvd player\",\n",
        "    \"emulator\", \"energy saver\", \"fiber optic\", \"game console\",\n",
        "    \"gps\", \"graphics processor\", \"hdmi\", \"hd\", \"high fidelity\",\n",
        "    \"iot\", \"iot device\", \"kinect\", \"lcd\", \"led tv\", \"li-polymer\",\n",
        "    \"machine learning\", \"media player\", \"microprocessor\",\n",
        "    \"nano board\", \"oscillator\", \"optical drive\", \"piezo\",\n",
        "    \"power cord\", \"power supply\", \"projector screen\",\n",
        "    \"radio\", \"receiver\", \"remote control\", \"rgb\",\n",
        "    \"robotics\", \"satellite\", \"set-top box\", \"signal processor\",\n",
        "    \"smart home\", \"smart device\", \"solar panel\", \"solid state\",\n",
        "    \"sound bar\", \"surveillance\", \"switch\", \"synthesizer\",\n",
        "    \"thermometer\", \"thunderbolt\", \"trackpad\", \"ups\", \"usb-c\",\n",
        "    \"vga\", \"video card\", \"video processor\", \"voice assistant\",\n",
        "    \"voltage regulator\", \"wearable device\", \"wifi extender\",\n",
        "    \"wire\", \"wireless router\", \"workstation computer\",\n",
        "    \"z-wave\", \"zigbee\", \"ac adapter\", \"amplifier\",\n",
        "    \"bluetooth speaker\", \"cable adapter\", \"circuit board\",\n",
        "    \"connector\", \"data storage\", \"digital clock\",\n",
        "    \"electronic component\", \"ethernet cable\", \"gaming headset\",\n",
        "    \"hard drive\", \"headphones\", \"infrared sensor\", \"input device\",\n",
        "    \"lithium battery\", \"microcontroller\", \"modem\", \"monitor\",\n",
        "    \"motion sensor\", \"network card\", \"network switch\", \"pcb board\",\n",
        "    \"pc gaming\", \"power adapter\", \"ram\", \"sd card\",\n",
        "    \"security camera\", \"server\", \"smart plug\", \"smart thermostat\",\n",
        "    \"speaker system\", \"ssd\", \"tablet\", \"touch screen\",\n",
        "    \"tv tuner\", \"usb adapter\", \"vr headset\",\n",
        "    \"wireless keyboard\", \"wireless mouse\", \"workstation\", \"zip drive\"\n",
        "]\n",
        "\n",
        "# Fungsi untuk memeriksa apakah teks mengandung kata kunci\n",
        "def contains_keywords(text, keywords):\n",
        "    return any(keyword in text.lower() for keyword in keywords)\n",
        "\n",
        "# Menambahkan kolom 'is_electronics' untuk menandai entri yang relevan\n",
        "df['is_electronics'] = df['text'].apply(lambda x: contains_keywords(x, keywords))\n",
        "\n",
        "# Menghitung jumlah data yang relevan dengan elektronik\n",
        "count_electronics = df['is_electronics'].sum()\n",
        "\n",
        "# Menampilkan jumlah entri yang relevan\n",
        "print(f\"Jumlah entri yang terkait dengan elektronik atau sinonimnya: {count_electronics}\")\n",
        "\n",
        "# Opsional: Tampilkan entri yang relevan\n",
        "print(df[df['is_electronics']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5HWbostiHPE",
        "outputId": "07183c3f-c955-475f-aedc-ab53cb441a32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah entri yang terkait dengan elektronik atau sinonimnya: 736350\n",
            "           title                                               text  \\\n",
            "1         autism  autism neurodevelopment disord character impai...   \n",
            "2         albedo  albedo measur reflect optic bright latin albed...   \n",
            "6       aristotl  aristotl greek ἀριστοτέλης pronounc aristotélɛ...   \n",
            "7  american pari  american pari jazz-influenc orchestr piec amer...   \n",
            "9  academi award  academi award known offici oscar set twenty-fo...   \n",
            "\n",
            "   is_electronics  \n",
            "1            True  \n",
            "2            True  \n",
            "6            True  \n",
            "7            True  \n",
            "9            True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyeimbangkan Data (Opsional jika ketidakseimbangan terjadi)\n",
        "data_electronics = df[df['is_electronics']]\n",
        "data_non_electronics = df[~df['is_electronics']]\n",
        "\n",
        "# Duplicate data elektronik hingga jumlahnya setara dengan data lainnya\n",
        "balanced_data = pd.concat([data_electronics, data_non_electronics.sample(len(data_electronics), replace=True)])"
      ],
      "metadata": {
        "id": "ykZGS6kZiHMM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset untuk training dan testing\n",
        "train_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RwjvFyariHJe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menambahkan kolom 'fasttext_label' ke kedua dataset: train_data dan test_data\n",
        "train_data['fasttext_label'] = train_data['is_electronics'].apply(lambda x: '__label__electronics' if x else '__label__none')\n",
        "test_data['fasttext_label'] = test_data['is_electronics'].apply(lambda x: '__label__electronics' if x else '__label__none')\n",
        "\n",
        "# Menyimpan data ke file teks untuk pelatihan FastText\n",
        "train_data[['fasttext_label', 'text']].to_csv('/content/drive/MyDrive/Google Colab TA/fasttext_train.txt', index=False, sep=' ', header=False)\n",
        "test_data[['fasttext_label', 'text']].to_csv('/content/drive/MyDrive/Google Colab TA/fasttext_test.txt', index=False, sep=' ', header=False)\n",
        "\n",
        "print(\"Data untuk FastText telah berhasil disimpan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V18AOXR3iHGw",
        "outputId": "e4a05025-29d8-46b5-d5e2-2d11e84e22df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data untuk FastText telah berhasil disimpan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi Teks dengan Tokenizer BERT\n",
        "# Load tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Fungsi tokenisasi\n",
        "def tokenize_text(text):\n",
        "    return tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Tokenisasi data training dan testing\n",
        "def preprocess_bert_data(df):\n",
        "    df['tokenized'] = df['text'].apply(tokenize_text)\n",
        "    return df\n",
        "\n",
        "train_data = preprocess_bert_data(train_data)\n",
        "test_data = preprocess_bert_data(test_data)\n",
        "\n",
        "train_data.to_pickle('/content/drive/MyDrive/Google Colab TA/distilbert_train_compressed.pkl', compression='gzip')\n",
        "test_data.to_pickle('/content/drive/MyDrive/Google Colab TA/distilbert_test_compressed.pkl', compression='gzip')\n",
        "\n",
        "print(\"Proses data preparation selesai dengan kompresi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA9eiLxNiHEF",
        "outputId": "a31dcbcb-0f08-4155-dfde-c2138a0f60e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses data preparation selesai dengan kompresi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnPopijDiHBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1yfw5kWCiG-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}